"""
Export YOLOv8 best.pt ‚Üí ONNX / TensorRT ‡πÅ‡∏•‡∏∞ Deploy ‡πÑ‡∏õ‡∏¢‡∏±‡∏á models/
==================================================================
‡∏£‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß:

  # Export ‡πÄ‡∏õ‡πá‡∏ô ONNX (‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å hardware)
  python scripts/export_model.py --weights runs/train/vehicle_detector_XXXXX/weights/best.pt --format onnx

  # Export ‡πÄ‡∏õ‡πá‡∏ô TensorRT (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ GPU + TensorRT ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á)
  python scripts/export_model.py --weights runs/train/vehicle_detector_XXXXX/weights/best.pt --format engine

  # Export ‡πÅ‡∏•‡πâ‡∏ß deploy ‡πÑ‡∏õ‡∏¢‡∏±‡∏á models/ ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
  python scripts/export_model.py --weights runs/train/vehicle_detector_XXXXX/weights/best.pt --format onnx --deploy
"""

import os
import sys
import shutil
import argparse
import logging
from pathlib import Path
from datetime import datetime

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
log = logging.getLogger(__name__)

MODELS_DIR = Path("./models")
DOCKER_COMPOSE_PATH = Path("./docker-compose.yml")


def validate_model(weights_path: Path) -> bool:
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô export"""
    try:
        from ultralytics import YOLO
        import numpy as np

        log.info(f"üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•: {weights_path}")
        model = YOLO(str(weights_path))

        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ dummy image
        dummy = np.zeros((640, 640, 3), dtype="uint8")
        results = model.predict(dummy, verbose=False, conf=0.25, classes=[0])

        log.info(f"   ‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥")
        log.info(f"   Classes: {model.names}")
        log.info(f"   Input size: {model.overrides.get('imgsz', 640)}")
        return True

    except Exception as e:
        log.error(f"‚ùå ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: {e}")
        return False


def export_onnx(weights_path: Path, imgsz: int = 640, opset: int = 17,
                simplify: bool = True, dynamic: bool = False) -> Path:
    """
    Export best.pt ‚Üí ONNX
    ONNX ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å hardware ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ GPU
    """
    try:
        from ultralytics import YOLO
    except ImportError:
        log.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö ultralytics ‚Äî pip install ultralytics")
        sys.exit(1)

    log.info("üì¶ Export ‚Üí ONNX")
    log.info(f"   imgsz={imgsz}, opset={opset}, simplify={simplify}")

    model = YOLO(str(weights_path))
    export_path = model.export(
        format="onnx",
        imgsz=imgsz,
        opset=opset,
        simplify=simplify,
        dynamic=dynamic,
        half=False,         # FP32 (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Å‡∏ß‡πà‡∏≤ FP16 ‡∏ö‡∏ô CPU)
    )

    onnx_file = Path(str(weights_path).replace(".pt", ".onnx"))
    if not onnx_file.exists():
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå .onnx ‡∏ó‡∏µ‡πà export
        onnx_file = Path(export_path) if export_path else None

    if onnx_file and onnx_file.exists():
        log.info(f"   ‚úÖ ONNX: {onnx_file} ({onnx_file.stat().st_size / 1e6:.1f} MB)")
        return onnx_file
    else:
        log.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå ONNX ‡∏´‡∏•‡∏±‡∏á export")
        return None


def export_tensorrt(weights_path: Path, imgsz: int = 640,
                    half: bool = True, batch: int = 1,
                    workspace: int = 4) -> Path:
    """
    Export best.pt ‚Üí TensorRT (.engine)
    ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£: NVIDIA GPU + TensorRT ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á (‡∏°‡∏±‡∏Å‡∏°‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏° CUDA)
    ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ ONNX 3-5x ‡∏ö‡∏ô GPU
    """
    try:
        from ultralytics import YOLO
    except ImportError:
        log.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö ultralytics ‚Äî pip install ultralytics")
        sys.exit(1)

    log.info("‚ö° Export ‚Üí TensorRT (.engine)")
    log.info(f"   imgsz={imgsz}, half={half}, batch={batch}, workspace={workspace}GB")
    log.info("   (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 5-15 ‡∏ô‡∏≤‡∏ó‡∏µ...)")

    model = YOLO(str(weights_path))
    export_path = model.export(
        format="engine",
        imgsz=imgsz,
        half=half,           # FP16 (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤, ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ GPU ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)
        batch=batch,
        workspace=workspace,
        simplify=True,
        verbose=True,
    )

    engine_file = Path(str(weights_path).replace(".pt", ".engine"))
    if not engine_file.exists():
        engine_file = Path(export_path) if export_path else None

    if engine_file and engine_file.exists():
        log.info(f"   ‚úÖ TensorRT: {engine_file} ({engine_file.stat().st_size / 1e6:.1f} MB)")
        return engine_file
    else:
        log.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå .engine ‡∏´‡∏•‡∏±‡∏á export")
        return None


def deploy_model(model_file: Path, target_name: str = None,
                 update_compose: bool = True) -> bool:
    """
    Copy ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á models/ ‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï docker-compose.yml
    """
    MODELS_DIR.mkdir(parents=True, exist_ok=True)

    suffix = model_file.suffix  # .pt, .onnx, .engine

    if target_name is None:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠ backup ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏±‡∏ö
        target_name = f"vehicle_detector{suffix}"

    dest = MODELS_DIR / target_name
    backup_name = f"vehicle_detector_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}{suffix}"
    backup = MODELS_DIR / backup_name

    # Backup ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡πà‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    if dest.exists():
        shutil.copy2(dest, backup)
        log.info(f"   üíæ Backup: {backup}")

    # Copy ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà
    shutil.copy2(model_file, dest)
    log.info(f"   ‚úÖ Deploy: {dest}")

    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï VEHICLE_MODEL_PATH ‡πÉ‡∏ô docker-compose.yml
    if update_compose and DOCKER_COMPOSE_PATH.exists():
        _update_docker_compose(dest)

    return True


def _update_docker_compose(model_path: Path):
    """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï VEHICLE_MODEL_PATH ‡πÉ‡∏ô docker-compose.yml"""
    try:
        content = DOCKER_COMPOSE_PATH.read_text(encoding="utf-8")
        filename = model_path.name
        docker_path = f"/models/{filename}"

        # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà VEHICLE_MODEL_PATH ‡∏ó‡∏∏‡∏Å‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
        import re
        new_content = re.sub(
            r"(VEHICLE_MODEL_PATH:\s*).*",
            f"\\1{docker_path}",
            content
        )

        if new_content != content:
            DOCKER_COMPOSE_PATH.write_text(new_content, encoding="utf-8")
            log.info(f"   ‚úÖ docker-compose.yml ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï VEHICLE_MODEL_PATH={docker_path}")
        else:
            log.warning("   ‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö VEHICLE_MODEL_PATH ‡πÉ‡∏ô docker-compose.yml")

    except Exception as e:
        log.error(f"   ‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï docker-compose.yml: {e}")


def test_deployed_model(model_path: Path):
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà deploy ‡πÅ‡∏•‡πâ‡∏ß"""
    try:
        from ultralytics import YOLO
        import numpy as np
        import time

        log.info(f"\nüß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà deploy: {model_path}")
        model = YOLO(str(model_path))

        dummy = np.random.randint(0, 255, (640, 640, 3), dtype="uint8")

        # Warmup
        for _ in range(3):
            model.predict(dummy, verbose=False, conf=0.25, classes=[0])

        # Benchmark
        times = []
        for _ in range(10):
            t0 = time.perf_counter()
            model.predict(dummy, verbose=False, conf=0.25, classes=[0])
            times.append((time.perf_counter() - t0) * 1000)

        avg_ms = sum(times) / len(times)
        log.info(f"   ‚úÖ Inference: {avg_ms:.1f}ms / frame ({1000/avg_ms:.0f} FPS max)")
        log.info(f"   Classes: {model.names}")

    except Exception as e:
        log.error(f"   ‚ùå ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")


def main():
    parser = argparse.ArgumentParser(
        description="Export YOLOv8 weights ‡πÅ‡∏•‡∏∞ Deploy ‡πÑ‡∏õ‡∏¢‡∏±‡∏á models/",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument("--weights", required=True,
                        help="Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á best.pt (‡∏à‡∏≤‡∏Å runs/train/.../weights/best.pt)")
    parser.add_argument("--format", choices=["onnx", "engine", "pt"],
                        default="onnx",
                        help="‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö export: onnx=CPU/GPU ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ, engine=TensorRT GPU ‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏∏‡∏î")
    parser.add_argument("--imgsz", type=int, default=640,
                        help="‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô)")
    parser.add_argument("--deploy", action="store_true",
                        help="Copy ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á models/ ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥")
    parser.add_argument("--deploy-name", default=None,
                        help="‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô vehicle_detector.onnx")
    parser.add_argument("--validate", action="store_true", default=True,
                        help="‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô export")
    parser.add_argument("--no-validate", action="store_false", dest="validate")
    parser.add_argument("--test-after-deploy", action="store_true",
                        help="‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏±‡∏á deploy")
    # TensorRT options
    parser.add_argument("--half", action="store_true", default=True,
                        help="TensorRT FP16 (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤, ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ GPU)")
    parser.add_argument("--workspace", type=int, default=4,
                        help="TensorRT workspace (GB)")

    args = parser.parse_args()

    weights_path = Path(args.weights)

    if not weights_path.exists():
        log.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå weights: {weights_path}")
        sys.exit(1)

    log.info("=" * 60)
    log.info("üöÄ Export ‡πÅ‡∏•‡∏∞ Deploy YOLOv8 Vehicle Detector")
    log.info("=" * 60)
    log.info(f"  Weights : {weights_path}")
    log.info(f"  Format  : {args.format}")
    log.info(f"  imgsz   : {args.imgsz}")
    log.info("=" * 60)

    # Validate ‡∏Å‡πà‡∏≠‡∏ô
    if args.validate:
        if not validate_model(weights_path):
            log.error("‚ùå ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‚Äî ‡∏´‡∏¢‡∏∏‡∏î export")
            sys.exit(1)

    # Export
    exported_file = None

    if args.format == "pt":
        exported_file = weights_path
        log.info("   ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå .pt ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á export)")

    elif args.format == "onnx":
        exported_file = export_onnx(weights_path, imgsz=args.imgsz)

    elif args.format == "engine":
        exported_file = export_tensorrt(
            weights_path,
            imgsz=args.imgsz,
            half=args.half,
            workspace=args.workspace,
        )

    if exported_file is None:
        log.error("‚ùå Export ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
        sys.exit(1)

    log.info(f"\n‚úÖ Export ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {exported_file}")

    # Deploy
    if args.deploy:
        log.info("\nüì§ Deploy ‡πÑ‡∏õ‡∏¢‡∏±‡∏á models/...")
        success = deploy_model(exported_file, target_name=args.deploy_name)

        if success and args.test_after_deploy:
            deploy_name = args.deploy_name or f"vehicle_detector{exported_file.suffix}"
            test_deployed_model(MODELS_DIR / deploy_name)

        log.info("\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!")
        log.info("   ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ:")
        log.info("   docker compose up -d --build backend")
    else:
        log.info("\nüí° ‡∏ñ‡πâ‡∏≤‡∏û‡∏≠‡πÉ‡∏à‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏£‡∏±‡∏ô:")
        log.info(f"   python scripts/export_model.py --weights {weights_path} "
                 f"--format {args.format} --deploy")
        log.info("   ‡πÅ‡∏•‡πâ‡∏ß: docker compose up -d --build backend")


if __name__ == "__main__":
    main()
