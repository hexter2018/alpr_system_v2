"""
Fine-tune YOLOv8n à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸£à¸–à¸¢à¸™à¸•à¹Œ 4 à¸¥à¹‰à¸­ à¸ˆà¸²à¸à¸à¸¥à¹‰à¸­à¸‡à¸«à¸™à¹‰à¸²à¸‡à¸²à¸™à¸ˆà¸£à¸´à¸‡
===================================================================
à¸£à¸±à¸™: python scripts/train_vehicle_detector.py

à¸à¹ˆà¸­à¸™à¸£à¸±à¸™ à¸•à¹‰à¸­à¸‡à¸¡à¸µ:
  1. à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ ultralytics: pip install ultralytics
  2. à¹€à¸•à¸£à¸µà¸¢à¸¡ dataset à¹ƒà¸™à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸™à¸µà¹‰:
       dataset/
         images/train/*.jpg   (à¸ à¸²à¸à¹€à¸—à¸£à¸™)
         images/val/*.jpg     (à¸ à¸²à¸ validate)
         labels/train/*.txt   (label YOLO format)
         labels/val/*.txt
  3. à¹à¸à¹‰ DATA_YAML_PATH à¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡

à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™ Labeling (à¸à¹ˆà¸­à¸™à¹€à¸—à¸£à¸™):
  Option A) Roboflow (à¹à¸™à¸°à¸™à¸³ â€” à¸Ÿà¸£à¸µà¹à¸¥à¸°à¸‡à¹ˆà¸²à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸”):
    1. à¹„à¸›à¸—à¸µà¹ˆ https://roboflow.com â†’ à¸ªà¸£à¹‰à¸²à¸‡ Project à¹ƒà¸«à¸¡à¹ˆ
    2. Upload à¸ à¸²à¸à¸—à¸µà¹ˆà¸ªà¸à¸±à¸”à¹„à¸”à¹‰à¸ˆà¸²à¸ extract_frames.py
    3. à¸•à¸µà¸à¸£à¸­à¸šà¸£à¸–à¸—à¸¸à¸à¸„à¸±à¸™à¹ƒà¸™à¸—à¸¸à¸à¸ à¸²à¸ (class 0: car)
    4. Export à¹€à¸›à¹‡à¸™ "YOLOv8" format â†’ Download ZIP
    5. à¹à¸•à¸ ZIP à¸§à¸²à¸‡à¹ƒà¸™ dataset/

  Option B) LabelImg (offline):
    pip install labelImg
    labelImg dataset/images/train dataset/labels/train
    (à¹€à¸¥à¸·à¸­à¸ YOLO format, à¸à¸³à¸«à¸™à¸” class = car)

  Option C) CVAT (self-hosted/cloud):
    https://cvat.ai â†’ upload â†’ annotate â†’ export YOLO format
"""

import os
import sys
import shutil
import argparse
import logging
from pathlib import Path
from datetime import datetime

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
log = logging.getLogger(__name__)

# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# à¹à¸à¹‰ path à¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸à¸±à¸šà¸£à¸°à¸šà¸šà¸‚à¸­à¸‡à¸„à¸¸à¸“

# Path à¹„à¸›à¸¢à¸±à¸‡ data.yaml
DATA_YAML_PATH = "./scripts/training/data.yaml"

# Pre-trained weights (à¸ˆà¸°à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸”à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ)
PRETRAINED_WEIGHTS = "yolov8n.pt"

# à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¹€à¸à¹‡à¸šà¸œà¸¥à¹€à¸—à¸£à¸™
RUNS_DIR = "./runs/train"

# â”€â”€â”€ TRAINING PARAMS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TRAINING_CONFIG = {
    "epochs": 100,           # à¸ˆà¸³à¸™à¸§à¸™à¸£à¸­à¸šà¹€à¸—à¸£à¸™ (50 = à¹€à¸£à¹‡à¸§à¸à¸­à¹ƒà¸Šà¹‰, 100 = à¸”à¸µà¸à¸§à¹ˆà¸², 150 = à¸”à¸µà¸¡à¸²à¸)
    "imgsz": 640,            # à¸‚à¸™à¸²à¸”à¸ à¸²à¸ (640 = à¸¡à¸²à¸•à¸£à¸à¸²à¸™ YOLOv8)
    "batch": 16,             # à¸¥à¸”à¹€à¸«à¸¥à¸·à¸­ 8 à¸–à¹‰à¸² RAM/VRAM à¹„à¸¡à¹ˆà¸à¸­
    "patience": 20,          # à¸«à¸¢à¸¸à¸”à¸à¹ˆà¸­à¸™à¸–à¹‰à¸² val/mAP à¹„à¸¡à¹ˆà¸”à¸µà¸‚à¸¶à¹‰à¸™à¹ƒà¸™ 20 epochs (early stopping)
    "save_period": 10,       # à¸šà¸±à¸™à¸—à¸¶à¸ checkpoint à¸—à¸¸à¸ 10 epochs
    "workers": 4,            # à¸ˆà¸³à¸™à¸§à¸™ CPU threads (à¸¥à¸”à¹€à¸«à¸¥à¸·à¸­ 2 à¸–à¹‰à¸²à¸Šà¹‰à¸²)
    "cache": "ram",          # cache à¸ à¸²à¸à¹ƒà¸™ RAM à¹€à¸à¸·à¹ˆà¸­à¸„à¸§à¸²à¸¡à¹€à¸£à¹‡à¸§ ("disk" à¸–à¹‰à¸² RAM à¹„à¸¡à¹ˆà¸à¸­)
    "optimizer": "AdamW",    # optimizer
    "lr0": 0.001,            # learning rate à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™
    "lrf": 0.01,             # learning rate à¸›à¸¥à¸²à¸¢ (lrf * lr0)
    "warmup_epochs": 3,      # ramp-up epochs
    "close_mosaic": 10,      # à¸›à¸´à¸” mosaic augmentation à¸Šà¹ˆà¸§à¸‡ 10 epochs à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢
    "augment": True,         # à¹€à¸›à¸´à¸” augmentation (flip, hsv, mosaic à¸¯à¸¥à¸¯)
    "hsv_h": 0.015,          # hue augmentation
    "hsv_s": 0.7,            # saturation augmentation
    "hsv_v": 0.4,            # value/brightness augmentation (à¸ªà¸³à¸„à¸±à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸¥à¸²à¸‡à¸„à¸·à¸™)
    "degrees": 5.0,          # rotation (à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢ â€” à¸à¸¥à¹‰à¸­à¸‡à¸¡à¸±à¸à¸™à¸´à¹ˆà¸‡)
    "translate": 0.1,        # translation
    "scale": 0.5,            # scale
    "fliplr": 0.5,           # horizontal flip
    "mosaic": 1.0,           # mosaic probability
    "mixup": 0.1,            # mixup probability
    "conf": 0.001,           # confidence threshold à¸•à¸­à¸™ val
    "iou": 0.6,              # IoU threshold à¸•à¸­à¸™ val
    "single_cls": True,      # à¸šà¸­à¸à¸§à¹ˆà¸²à¸¡à¸µà¹à¸„à¹ˆ 1 class (à¸ªà¸³à¸„à¸±à¸!)
    "verbose": True,
}


def check_dataset(data_yaml: Path) -> bool:
    """à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² dataset à¸à¸£à¹‰à¸­à¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸—à¸£à¸™à¸«à¸£à¸·à¸­à¸¢à¸±à¸‡"""
    import yaml

    if not data_yaml.exists():
        log.error(f"âŒ à¹„à¸¡à¹ˆà¸à¸š data.yaml: {data_yaml}")
        return False

    with open(data_yaml) as f:
        cfg = yaml.safe_load(f)

    dataset_root = Path(cfg.get("path", "."))
    if not dataset_root.is_absolute():
        dataset_root = data_yaml.parent / dataset_root

    train_img = dataset_root / cfg.get("train", "images/train")
    val_img = dataset_root / cfg.get("val", "images/val")
    train_lbl = Path(str(train_img).replace("images", "labels"))
    val_lbl = Path(str(val_img).replace("images", "labels"))

    log.info("ğŸ“‚ à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Dataset:")
    issues = []

    for name, path in [("train/images", train_img), ("val/images", val_img),
                        ("train/labels", train_lbl), ("val/labels", val_lbl)]:
        if not path.exists():
            issues.append(f"   âŒ {name}: {path} â€” à¹„à¸¡à¹ˆà¸à¸šà¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ")
        else:
            files = list(path.glob("*.*"))
            log.info(f"   âœ… {name}: {len(files)} à¹„à¸Ÿà¸¥à¹Œ")

    if issues:
        for issue in issues:
            log.error(issue)
        return False

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² label à¸¡à¸µà¸à¸­
    train_labels = list(train_lbl.glob("*.txt"))
    val_labels = list(val_lbl.glob("*.txt"))

    if len(train_labels) < 50:
        log.warning(f"âš ï¸ à¸ à¸²à¸ train ({len(train_labels)}) à¸™à¹‰à¸­à¸¢à¹€à¸à¸´à¸™à¹„à¸› â€” à¹à¸™à¸°à¸™à¸³ â‰¥ 200 à¸ à¸²à¸")
    if len(val_labels) < 20:
        log.warning(f"âš ï¸ à¸ à¸²à¸ val ({len(val_labels)}) à¸™à¹‰à¸­à¸¢à¹€à¸à¸´à¸™à¹„à¸› â€” à¹à¸™à¸°à¸™à¸³ â‰¥ 50 à¸ à¸²à¸")

    log.info(f"\n   à¸ªà¸£à¸¸à¸›: Train={len(train_labels)} à¸ à¸²à¸, Val={len(val_labels)} à¸ à¸²à¸")
    return True


def split_dataset(raw_dir: Path, output_dir: Path,
                  train_ratio: float = 0.80, val_ratio: float = 0.15):
    """
    à¹à¸šà¹ˆà¸‡ Dataset à¸ˆà¸²à¸ raw images à¸—à¸µà¹ˆà¸¡à¸µ label à¹à¸¥à¹‰à¸§ â†’ train/val/test
    à¹ƒà¸Šà¹‰à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸ label à¸ à¸²à¸à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§

    raw_dir à¸•à¹‰à¸­à¸‡à¸¡à¸µà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡:
      raw_dir/images/*.jpg
      raw_dir/labels/*.txt  (YOLO format)
    """
    import random
    import yaml

    img_dir = raw_dir / "images"
    lbl_dir = raw_dir / "labels"

    images = sorted(img_dir.glob("*.jpg")) + sorted(img_dir.glob("*.png"))
    log.info(f"ğŸ“¦ à¸à¸š {len(images)} à¸ à¸²à¸à¹ƒà¸™ {img_dir}")

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µ label à¸„à¸£à¸š
    images_with_labels = [img for img in images if (lbl_dir / (img.stem + ".txt")).exists()]
    log.info(f"   à¸¡à¸µ label: {len(images_with_labels)}/{len(images)} à¸ à¸²à¸")

    if len(images_with_labels) < 10:
        log.error("âŒ à¸ à¸²à¸à¸—à¸µà¹ˆà¸¡à¸µ label à¸™à¹‰à¸­à¸¢à¹€à¸à¸´à¸™à¹„à¸› â€” à¸•à¹‰à¸­à¸‡ label à¸à¹ˆà¸­à¸™!")
        return

    random.seed(42)
    random.shuffle(images_with_labels)

    n = len(images_with_labels)
    n_train = int(n * train_ratio)
    n_val = int(n * val_ratio)

    splits = {
        "train": images_with_labels[:n_train],
        "val": images_with_labels[n_train:n_train + n_val],
        "test": images_with_labels[n_train + n_val:],
    }

    for split_name, split_imgs in splits.items():
        out_img = output_dir / "images" / split_name
        out_lbl = output_dir / "labels" / split_name
        out_img.mkdir(parents=True, exist_ok=True)
        out_lbl.mkdir(parents=True, exist_ok=True)

        for img_path in split_imgs:
            lbl_path = lbl_dir / (img_path.stem + ".txt")
            shutil.copy2(img_path, out_img / img_path.name)
            if lbl_path.exists():
                shutil.copy2(lbl_path, out_lbl / lbl_path.name)

        log.info(f"   {split_name}: {len(split_imgs)} à¸ à¸²à¸ â†’ {out_img}")

    # à¸­à¸±à¸›à¹€à¸”à¸• data.yaml
    yaml_path = output_dir / "data.yaml"
    data_cfg = {
        "path": str(output_dir.resolve()),
        "train": "images/train",
        "val": "images/val",
        "test": "images/test",
        "nc": 1,
        "names": {0: "car"},
    }
    with open(yaml_path, "w") as f:
        yaml.dump(data_cfg, f, default_flow_style=False, allow_unicode=True)

    log.info(f"\nâœ… à¹à¸šà¹ˆà¸‡ Dataset à¹€à¸ªà¸£à¹‡à¸ˆ â†’ {output_dir}")
    log.info(f"   data.yaml: {yaml_path}")
    return yaml_path


def train(data_yaml: str, weights: str, run_name: str = None, **overrides):
    """à¸£à¸±à¸™ YOLOv8 Fine-tuning"""
    try:
        from ultralytics import YOLO
    except ImportError:
        log.error("âŒ à¹„à¸¡à¹ˆà¸à¸š ultralytics â€” à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¸”à¹‰à¸§à¸¢: pip install ultralytics")
        sys.exit(1)

    if run_name is None:
        run_name = datetime.now().strftime("vehicle_detector_%Y%m%d_%H%M")

    log.info("=" * 60)
    log.info("ğŸš€ à¹€à¸£à¸´à¹ˆà¸¡ Fine-tune YOLOv8 à¸ªà¸³à¸«à¸£à¸±à¸š Vehicle Detection")
    log.info("=" * 60)
    log.info(f"  Weights    : {weights}")
    log.info(f"  Data YAML  : {data_yaml}")
    log.info(f"  Run name   : {run_name}")
    log.info(f"  Epochs     : {overrides.get('epochs', TRAINING_CONFIG['epochs'])}")
    log.info(f"  Image size : {overrides.get('imgsz', TRAINING_CONFIG['imgsz'])}")
    log.info(f"  Batch size : {overrides.get('batch', TRAINING_CONFIG['batch'])}")
    log.info("=" * 60)

    # à¹‚à¸«à¸¥à¸” model
    model = YOLO(weights)

    # à¸£à¸§à¸¡ config
    train_args = {**TRAINING_CONFIG, **overrides}
    train_args["data"] = data_yaml
    train_args["name"] = run_name
    train_args["project"] = RUNS_DIR

    # à¹€à¸—à¸£à¸™!
    results = model.train(**train_args)

    # à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
    log.info("\n" + "=" * 60)
    log.info("ğŸ‰ à¹€à¸—à¸£à¸™à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™!")
    log.info("=" * 60)

    best_pt = Path(RUNS_DIR) / run_name / "weights" / "best.pt"
    last_pt = Path(RUNS_DIR) / run_name / "weights" / "last.pt"

    if best_pt.exists():
        log.info(f"  âœ… Best weights : {best_pt}")
        log.info(f"  ğŸ“Š Metrics :")
        try:
            metrics = results.results_dict
            log.info(f"     mAP50   = {metrics.get('metrics/mAP50(B)', 0):.4f}")
            log.info(f"     mAP50-95= {metrics.get('metrics/mAP50-95(B)', 0):.4f}")
            log.info(f"     Precision= {metrics.get('metrics/precision(B)', 0):.4f}")
            log.info(f"     Recall   = {metrics.get('metrics/recall(B)', 0):.4f}")
        except Exception:
            pass

    log.info(f"\n  à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸–à¸±à¸”à¹„à¸›:")
    log.info(f"  1. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸œà¸¥: runs/train/{run_name}/")
    log.info(f"  2. Export à¹‚à¸¡à¹€à¸”à¸¥: python scripts/export_model.py --weights {best_pt}")

    return results, best_pt


def main():
    parser = argparse.ArgumentParser(
        description="Fine-tune YOLOv8n à¸ªà¸³à¸«à¸£à¸±à¸š Vehicle Detection",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    subparsers = parser.add_subparsers(dest="command")

    # à¸„à¸³à¸ªà¸±à¹ˆà¸‡: split (à¹à¸šà¹ˆà¸‡ dataset)
    split_parser = subparsers.add_parser("split", help="à¹à¸šà¹ˆà¸‡ raw dataset â†’ train/val/test")
    split_parser.add_argument("--raw-dir", default="./dataset/raw",
                              help="à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¸ à¸²à¸ raw (à¸•à¹‰à¸­à¸‡à¸¡à¸µ images/ à¹à¸¥à¸° labels/)")
    split_parser.add_argument("--output-dir", default="./dataset",
                              help="à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ output")
    split_parser.add_argument("--train-ratio", type=float, default=0.80)
    split_parser.add_argument("--val-ratio", type=float, default=0.15)

    # à¸„à¸³à¸ªà¸±à¹ˆà¸‡: train
    train_parser = subparsers.add_parser("train", help="à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥")
    train_parser.add_argument("--data", default=DATA_YAML_PATH,
                              help="path à¹„à¸›à¸¢à¸±à¸‡ data.yaml")
    train_parser.add_argument("--weights", default=PRETRAINED_WEIGHTS,
                              help="Pre-trained weights (.pt)")
    train_parser.add_argument("--epochs", type=int, default=TRAINING_CONFIG["epochs"])
    train_parser.add_argument("--batch", type=int, default=TRAINING_CONFIG["batch"])
    train_parser.add_argument("--imgsz", type=int, default=TRAINING_CONFIG["imgsz"])
    train_parser.add_argument("--name", default=None,
                              help="à¸Šà¸·à¹ˆà¸­ run (default: vehicle_detector_YYYYMMDD_HHMM)")
    train_parser.add_argument("--device", default="",
                              help="à¸­à¸¸à¸›à¸à¸£à¸“à¹Œ: 0=GPU0, cpu, 0,1=multi-GPU (à¸§à¹ˆà¸²à¸‡=auto)")

    # à¸„à¸³à¸ªà¸±à¹ˆà¸‡: check (à¸•à¸£à¸§à¸ˆ dataset)
    check_parser = subparsers.add_parser("check", help="à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š dataset à¸à¹ˆà¸­à¸™à¹€à¸—à¸£à¸™")
    check_parser.add_argument("--data", default=DATA_YAML_PATH)

    args = parser.parse_args()

    if args.command == "split":
        split_dataset(
            raw_dir=Path(args.raw_dir),
            output_dir=Path(args.output_dir),
            train_ratio=args.train_ratio,
            val_ratio=args.val_ratio,
        )

    elif args.command == "check":
        ok = check_dataset(Path(args.data))
        if ok:
            log.info("âœ… Dataset à¸à¸£à¹‰à¸­à¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸—à¸£à¸™")
        else:
            log.error("âŒ à¸à¸£à¸¸à¸“à¸²à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²à¸”à¹‰à¸²à¸™à¸šà¸™à¸à¹ˆà¸­à¸™à¹€à¸—à¸£à¸™")

    elif args.command == "train":
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š dataset à¸à¹ˆà¸­à¸™
        if not check_dataset(Path(args.data)):
            log.error("âŒ Dataset à¹„à¸¡à¹ˆà¸à¸£à¹‰à¸­à¸¡ â€” à¸«à¸¢à¸¸à¸”à¸à¸²à¸£à¹€à¸—à¸£à¸™")
            sys.exit(1)

        overrides = {
            "epochs": args.epochs,
            "batch": args.batch,
            "imgsz": args.imgsz,
        }
        if args.device:
            overrides["device"] = args.device

        train(
            data_yaml=args.data,
            weights=args.weights,
            run_name=args.name,
            **overrides,
        )

    else:
        parser.print_help()
        print("\nğŸ’¡ à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™:")
        print("  # 1. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š dataset:")
        print("  python scripts/train_vehicle_detector.py check --data scripts/training/data.yaml")
        print()
        print("  # 2. à¹à¸šà¹ˆà¸‡ dataset (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹à¸šà¹ˆà¸‡):")
        print("  python scripts/train_vehicle_detector.py split --raw-dir ./dataset/raw")
        print()
        print("  # 3. à¹€à¸—à¸£à¸™ (à¹ƒà¸Šà¹‰ GPU):")
        print("  python scripts/train_vehicle_detector.py train --data scripts/training/data.yaml --device 0")
        print()
        print("  # 4. à¹€à¸—à¸£à¸™ (à¹ƒà¸Šà¹‰ CPU - à¸Šà¹‰à¸²à¸à¸§à¹ˆà¸²):")
        print("  python scripts/train_vehicle_detector.py train --data scripts/training/data.yaml --device cpu --epochs 50")


if __name__ == "__main__":
    main()
